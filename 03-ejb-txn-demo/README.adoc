= Demonstrates remote EJB calls and transaction propagation

== What is it?

Project demonstrates the remote EJB calls over two application servers.

[cols="40%,60%",options="headers"]
|===
|Project |Description

|`client`
|An application that needs to be deployed to the first server. It contains an EJB which calls
 the EJB application on the second server.
 For the EJB processing will be enlisted to the JTA transaction and processed with the two-phase
 commit there is an execution of JMS message call.

|`server`
|An application which is about tobe deployed to the second server. It contains an EJB which is capable
 to receive a remote call from the first server.
 For the EJB processing being enlisted to the JTA transaction there is a database insertion
 being part of the logic in the EJB business method. Then there is a special XAResource
 enlisted to the transaction for purposes of this quickstart demonstration.

|===

== Setup the environment

We need 3 instances of WildFly. Tested with WildFly 19.0.0.Beta1.

[code, bash]
----
# dowload the zip distribution from http://wildfly.org
# client server: client.war
unzip ~/Downloads/wildfly-19.0.0.Beta1.zip; mv wildfly-19.0.0.Beta1/ wfly1
# server server: server.war
cp -r wfly1/ wfly2/
cp -r wfly1/ wfly3/
----

Configure the credentials for remote call authentication

[source,bash]
----
# go to the directory wfly2 and wfly3 and do the same
cd wfly2
# add user to 'ApplicationRealm' with command line tool
./bin/add-user.sh -a -u ejb -p ejb -ds
# with parameter -ds secret will be printed
## To represent the user add the following to the server-identities definition <secret value="ZWpi" />
----

Configure the client server with ejb security realm and remote outbound connection

[source,bash]
----
# 1. go to the directory with distribution of wfly1
cd wfly1
# 2. configure EJB remote endpoints
./bin/jboss-cli.sh --file=03-ejb-txn-demo/client/extensions/local-ejb-configuration.cli
# 3. configure JMS queue
./bin/jboss-cli.sh --file=03-ejb-txn-demo/client/extensions/local-jms-configuration.cli
----

Database is configured under `h2-ds.xml` descritor at `server`.

== Build, deploy and start WildFly

[source,sh]
----
# package and deploy
mvn clean package
cp client/target/client.war wfly1/standalone/deployments
cp server/target/server.war wfly2/standalone/deployments
cp server/target/server.war wfly3/standalone/deployments

# start server (each one on its console)
./bin/standalone.sh -c standalone-full.xml  -Djboss.tx.node.id=wfly1 -Djboss.node.name=wfly1
./bin/standalone.sh -c standalone-ha.xml -Djboss.tx.node.id=wfly2 -Djboss.node.name=wfly2 -Djboss.socket.binding.port-offset=100
./bin/standalone.sh -c standalone-ha.xml -Djboss.tx.node.id=wfly3 -Djboss.node.name=wfly3 -Djboss.socket.binding.port-offset=200
----

== Test the HTTP invocations

[source,sh]
----
# transactional stateless
curl -s localhost:8080/client/stateless-tx | jq .
# non-transactional stateless
curl -s localhost:8080/client/stateless-notx | jq .
# non-transactional stateful
curl -s localhost:8080/client/stateful-notx | jq .

# verify on server
curl -s localhost:8180/server/users | jq '.[].id'
curl -s localhost:8280/server/users | jq '.[].id'
curl -s localhost:8180/server/commits

# crash
curl -X DELETE localhost:8180/server/users && printf ':' && curl -X DELETE localhost:8280/server/users
curl -s localhost:8080/client/fail

# after invocation restart the crashed server (either wfly2 or wfly3)
# check number of users
curl -s localhost:8180/server/users
# force recovery to happen now
telnet localhost 4712
>> SCAN
----

== Build for Kubernetes

[source,bash]
----

----

For deploying this Quickstart to Kubernetes/Openshift container platform it is needed to realize some facts.
The application is deployed at the WildFly server which is running in a pod.
The pod is an ephemeral object that could be rescheduled, restarted or moved to a different machine by the platform.
This is favourable neither for transaction manager which requires a log to be saved per WildFly server instance
nor for EJB remoting which requires a stable remote endpoint to ensure the state and transaction affinity,
and which is used during EJB remote transaction recovery calls.
For this to work the platform has to offer some guarantees which are granted
by StatefulSet object in case of the Kubernetes/OpenShift.
The WildFly Operator uses the StatefulSet as the object to manage the WildFly with.

The WildFly Operator is the recommended way to manage the WildFly instances on Kubernetes/OpenShift.

=== Running on Kubernetes

For running the application on Kubernetes you need first to build a docker image that may be deployed.
The deployment process is managed by WildFly Operator. When Operator is correctly setup
then it pulls the docker image from a docker registry and starts the application server with the deployment.

==== Running on Kubernetes: build a docker image

[NOTE]
====
The base image to build the application for WildFly is `quay.io/repository/wildfly/wildfly-centos7`
====

The whole concept of the WildFly image builds are based on the https://github.com/openshift/source-to-image[s2i].
The *s2i* tooling takes a docker image (_quay.io/repository/wildfly/wildfly-centos7_ in WildFly case).
This image is enriched with a *s2i* logic which is invoked during build of provided source code.

The *s2i* logic is useful for deployment build for additional steps like configuring the application server.
Check the directories `client/extensions` and `server/extensions` where shell scripts executes the CLI commands to be executed.
The WildFly s2i does not know about the `extensions` directory but it knows how to work with
shell scripts named as `install.sh` and `postconfigure.sh`. On s2i build we need to inform about existence
of the directory with environmental variable `S2I_IMAGE_SOURCE_MOUNTS`.

Then there are directores `client/configuration` and `server/configuration`. The content of those
directories will be copied to the result image to directory `$JBOSS_HOME/standalone/configuraiton`.

In short the WildFly CLI scripts and other setup provides

* `client/configuration`
** xml descriptor of `wildlfly-config-url` property
* `server/configuration`
** properties file `application-users.properties` that configures a user `ejb` to be authorized on receiving EJB calls
* `client/extensions/remote-configuration.cli`
** sockets, security realm and remote outbound connection for connecting to the `server` deployment
** enabling transaction manager socket to accept calls to execute transaction recovery
** http socket client mapping for https://github.com/wildfly/wildfly/blob/master/docs/src/main/asciidoc/_developer-guide/ejb3/EJB_on_Kubernetes.adoc#ejb-configuration-for-kubernetes[EJB remoting works]
* `client/extensions/clustering.cli`
** adding jgroups extension and subsystem configuration
** reconfiguration of Infinispan caches for being distributed
** http socket client mapping for EJB remoting works


The client deployment then needs the `JAVA_OPTS` properties to be adjusted
with `wildlfly-config-url` command line argument which points to the XML descriptor.

* First install docker and https://github.com/openshift/source-to-image#installation[install the s2i].
* Second build the quickstart images which will be placed in the docker local registry
with names `wildfly-quickstarts/client` and `wildfly-quickstarts/server`.
+
[source,bash]
----
s2i build --context-dir ejb-txn-remote-call/client \
  -e MAVEN_OPTS="-Dcom.redhat.xpaas.repo.jbossorg" -e S2I_IMAGE_SOURCE_MOUNTS=extensions \
  -e JAVA_OPTS_APPEND='-Dwildfly.config.url=$JBOSS_HOME/standalone/configuration/custom-config.xml' \
  https://github.com/wildfly/quickstart \
  quay.io/repository/wildfly/wildfly-centos7 wildfly-quickstarts/client

s2i build --context-dir ejb-txn-remote-call/server \
  -e MAVEN_OPTS="-Dcom.redhat.xpaas.repo.jbossorg" S2I_IMAGE_SOURCE_MOUNTS=extensions \
  https://github.com/wildfly/quickstart \
  quay.io/repository/wildfly/wildfly-centos7 wildfly-quickstarts/server
----

[NOTE]
====
The WildFly *s2i* code, environmental properties and information about chain builds
can be found at https://github.com/wildfly/wildfly-s2i.
====

The result images `wildfly-quickstarts/client` and `wildfly-quickstarts/server` have to be pushed
to a docker registry. Then they may be used as images deployed to Kubernetes.

==== Running on Kubernetes: deploy with WildFly Operator

The WildFly Operator is deployed via Kubernetes `Deployment` object
which listen to changes at other Kubernetes object of type `CustomerResource`.
The WildFly Operator manages `CustomerResource` of kind `WildFlyServer`.

The WildFly Operator can be found at https://quay.io[Quay.io]
repository at https://quay.io/repository/wildfly/wildfly-operator
with source code at https://github.com/wildfly/wildfly-operator.

To start the `Deployment` has to be created on Kubernetes. The YAML definition can be found in
https://github.com/wildfly/wildfly-operator/blob/master/deploy/operator.yaml[WildFly Operator Github repository].

For deployment works right a https://github.com/wildfly/wildfly-operator/blob/master/deploy/service_account.yaml[service account],
https://github.com/wildfly/wildfly-operator/blob/master/deploy/role.yaml[a role] and
https://github.com/wildfly/wildfly-operator/blob/master/deploy/role_binding.yaml[a role binding] have to be created
in the Kubernetes cluster.

The follow-up step is creation of https://github.com/wildfly/wildfly-operator/blob/master/deploy/crds/wildfly_v1alpha1_wildflyserver_crd.yaml[`CustomResourceDefinition`]
(abbreviated as *CRD*) which defines what capabilities provides the Operator and which things may be configured for the `WildFlyServer` `CustomerResource`.

[NOTE]
====
If you clone the https://github.com/wildfly/wildfly-operator[WildFly Operator GitHub repository] to your
local disk you may use the prepared script https://github.com/wildfly/wildfly-operator/blob/master/build/run-minikube.sh[build/run-minikube.sh]
for that purpose.
====

The quickstart uses clustering.
The WildFly clustering works with https://github.com/jgroups-extras/jgroups-kubernetes[jgroups `KUBE_PING`]
protocol. This protocol requires having permission to list all available pods in scope of the `namespace`.
The `default` `ServiceAccount` does not have such permissions.
For development purposes it's possible to use
https://github.com/wildfly/wildfly-operator/blob/master/examples/clustering/crds/role_binding.yaml[`RoleBinding` definition from WildFly Operator repository].
The definition permits for the deployments to view details information about any Kubernetes object
inside of the current `namespace`.

When all this is setup and the WildFly Operator `Pod` is running we may prepare a definition
of the `CustomerResource` which makes the application deployed.
The `CustomerResource` definition points to the built images wildfly-quickstarts/client` and `wildfly-quickstarts/server`
which has to be pushed at some docker registry.

